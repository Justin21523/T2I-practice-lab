{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1731fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb-sd-samplers-cfg.ipynb\n",
    "# SD Scheduler/Sampler/CFG Systematic Comparison\n",
    "# Stage 1 - Cross-Family Inference Fundamentals\n",
    "\n",
    "# %% [1] Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (Ë§áË£ΩÂà∞ÊØèÊú¨ notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e22fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# [2] Fixed Test Parameters & Seeds (Reproducibility)\n",
    "# =============================================================================\n",
    "\n",
    "# Test configuration\n",
    "TEST_CONFIG = {\n",
    "    \"prompt\": \"a serene mountain lake at sunset, oil painting style, detailed reflections\",\n",
    "    \"negative_prompt\": \"blurry, low quality, distorted, oversaturated\",\n",
    "    \"width\": 512,\n",
    "    \"height\": 512,\n",
    "    \"seeds\": [42, 1337, 2024],  # Multiple seeds for robustness\n",
    "    \"smoke_mode\": os.getenv(\"SMOKE_MODE\", \"false\").lower() == \"true\",\n",
    "}\n",
    "\n",
    "# Scheduler matrix for comparison\n",
    "SCHEDULER_CONFIGS = {\n",
    "    \"DPMSolverMultistep\": {\"steps\": [15, 25, 50], \"optimal_cfg\": 7.5},\n",
    "    \"EulerDiscrete\": {\"steps\": [15, 25, 50], \"optimal_cfg\": 7.5},\n",
    "    \"EulerAncestral\": {\"steps\": [15, 25, 50], \"optimal_cfg\": 7.5},\n",
    "    \"DDIM\": {\"steps\": [20, 30, 50], \"optimal_cfg\": 7.5},\n",
    "    \"UniPCMultistep\": {\"steps\": [15, 25, 50], \"optimal_cfg\": 7.5},\n",
    "    \"DPMSolverSinglestep\": {\"steps\": [15, 25, 50], \"optimal_cfg\": 7.5},\n",
    "}\n",
    "\n",
    "# CFG scale test range\n",
    "CFG_SCALES = [3.5, 5.0, 7.5, 10.0, 12.0] if not TEST_CONFIG[\"smoke_mode\"] else [7.5]\n",
    "\n",
    "print(f\"[Config] Prompt: '{TEST_CONFIG['prompt'][:50]}...'\")\n",
    "print(\n",
    "    f\"[Config] Seeds: {TEST_CONFIG['seeds']}, Smoke mode: {TEST_CONFIG['smoke_mode']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3fe2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# [3] SD1.5 Pipeline Setup with Memory Optimization\n",
    "# =============================================================================\n",
    "\n",
    "from diffusers import (\n",
    "    StableDiffusionPipeline,\n",
    "    DPMSolverMultistepScheduler,\n",
    "    EulerDiscreteScheduler,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    "    DDIMScheduler,\n",
    "    UniPCMultistepScheduler,\n",
    "    DPMSolverSinglestepScheduler,\n",
    ")\n",
    "\n",
    "\n",
    "def create_sd15_pipeline():\n",
    "    \"\"\"Create memory-optimized SD1.5 pipeline\"\"\"\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\",\n",
    "        torch_dtype=torch.float16,\n",
    "        use_safetensors=True,\n",
    "        variant=\"fp16\",\n",
    "    )\n",
    "\n",
    "    # Memory optimizations for 8-12GB VRAM\n",
    "    pipe.enable_attention_slicing()\n",
    "    pipe.enable_model_cpu_offload()\n",
    "\n",
    "    # Enable xFormers if available\n",
    "    try:\n",
    "        pipe.enable_xformers_memory_efficient_attention()\n",
    "        print(\"[Optimization] xFormers enabled\")\n",
    "    except ImportError:\n",
    "        print(\"[Optimization] xFormers not available, using attention slicing\")\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "# Load pipeline\n",
    "print(\"[Loading] SD1.5 pipeline with memory optimizations...\")\n",
    "sd15_pipe = create_sd15_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df960d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# [4] Scheduler Factory & Benchmark Function\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def get_scheduler(scheduler_name, pipe):\n",
    "    \"\"\"Factory function to create schedulers\"\"\"\n",
    "    schedulers = {\n",
    "        \"DPMSolverMultistep\": DPMSolverMultistepScheduler,\n",
    "        \"EulerDiscrete\": EulerDiscreteScheduler,\n",
    "        \"EulerAncestral\": EulerAncestralDiscreteScheduler,\n",
    "        \"DDIM\": DDIMScheduler,\n",
    "        \"UniPCMultistep\": UniPCMultistepScheduler,\n",
    "        \"DPMSolverSinglestep\": DPMSolverSinglestepScheduler,\n",
    "    }\n",
    "\n",
    "    if scheduler_name not in schedulers:\n",
    "        raise ValueError(f\"Unknown scheduler: {scheduler_name}\")\n",
    "\n",
    "    return schedulers[scheduler_name].from_config(pipe.scheduler.config)\n",
    "\n",
    "\n",
    "def benchmark_generation(pipe, scheduler_name, steps, cfg_scale, seed):\n",
    "    \"\"\"Benchmark single generation with timing\"\"\"\n",
    "    # Set scheduler\n",
    "    pipe.scheduler = get_scheduler(scheduler_name, pipe)\n",
    "\n",
    "    # Generate with timing\n",
    "    generator = torch.manual_seed(seed)\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.autocast(\"cuda\"):\n",
    "        result = pipe(\n",
    "            prompt=TEST_CONFIG[\"prompt\"],\n",
    "            negative_prompt=TEST_CONFIG[\"negative_prompt\"],\n",
    "            width=TEST_CONFIG[\"width\"],\n",
    "            height=TEST_CONFIG[\"height\"],\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=cfg_scale,\n",
    "            generator=generator,\n",
    "        )\n",
    "\n",
    "    generation_time = time.time() - start_time\n",
    "\n",
    "    return {\n",
    "        \"image\": result.images[0],\n",
    "        \"time\": generation_time,\n",
    "        \"scheduler\": scheduler_name,\n",
    "        \"steps\": steps,\n",
    "        \"cfg_scale\": cfg_scale,\n",
    "        \"seed\": seed,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1997f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# [5] SD1.5 Scheduler Comparison Experiment\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[Experiment] Starting SD1.5 scheduler comparison...\")\n",
    "results = []\n",
    "\n",
    "for scheduler_name, config in SCHEDULER_CONFIGS.items():\n",
    "    print(f\"\\n  Testing {scheduler_name}...\")\n",
    "\n",
    "    for steps in config[\"steps\"]:\n",
    "        if TEST_CONFIG[\"smoke_mode\"] and steps > 15:\n",
    "            continue  # Skip longer steps in smoke mode\n",
    "\n",
    "        for seed in TEST_CONFIG[\"seeds\"]:\n",
    "            if TEST_CONFIG[\"smoke_mode\"] and seed != 42:\n",
    "                continue  # Only first seed in smoke mode\n",
    "\n",
    "            try:\n",
    "                result = benchmark_generation(\n",
    "                    sd15_pipe, scheduler_name, steps, config[\"optimal_cfg\"], seed\n",
    "                )\n",
    "                results.append(result)\n",
    "\n",
    "                # Save individual image\n",
    "                filename = f\"sd15_{scheduler_name}_{steps}steps_cfg{config['optimal_cfg']}_seed{seed}.png\"\n",
    "                result[\"image\"].save(output_dir / filename)\n",
    "\n",
    "                print(f\"    ‚úì {steps} steps, seed {seed}: {result['time']:.2f}s\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚úó Failed {scheduler_name} {steps} steps: {e}\")\n",
    "\n",
    "print(f\"\\n[Results] Generated {len(results)} images for SD1.5 scheduler comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# [6] CFG Scale Impact Analysis\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[Experiment] CFG scale impact analysis...\")\n",
    "cfg_results = []\n",
    "\n",
    "# Use best performing scheduler from previous test (typically DPMSolverMultistep)\n",
    "best_scheduler = \"DPMSolverMultistep\"\n",
    "optimal_steps = 25\n",
    "\n",
    "for cfg_scale in CFG_SCALES:\n",
    "    for seed in TEST_CONFIG[\"seeds\"]:\n",
    "        if TEST_CONFIG[\"smoke_mode\"] and seed != 42:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            result = benchmark_generation(\n",
    "                sd15_pipe, best_scheduler, optimal_steps, cfg_scale, seed\n",
    "            )\n",
    "            cfg_results.append(result)\n",
    "\n",
    "            # Save CFG comparison image\n",
    "            filename = f\"cfg_comparison_{best_scheduler}_{optimal_steps}steps_cfg{cfg_scale}_seed{seed}.png\"\n",
    "            result[\"image\"].save(output_dir / filename)\n",
    "\n",
    "            print(f\"  ‚úì CFG {cfg_scale}, seed {seed}: {result['time']:.2f}s\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Failed CFG {cfg_scale}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd30b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# [7] Performance Analysis & Visualization\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def analyze_results(results_list, analysis_type):\n",
    "    \"\"\"Analyze timing and create performance summary\"\"\"\n",
    "    if not results_list:\n",
    "        return {}\n",
    "\n",
    "    analysis = {\n",
    "        \"total_images\": len(results_list),\n",
    "        \"avg_time\": np.mean([r[\"time\"] for r in results_list]),\n",
    "        \"min_time\": min([r[\"time\"] for r in results_list]),\n",
    "        \"max_time\": max([r[\"time\"] for r in results_list]),\n",
    "        \"analysis_type\": analysis_type,\n",
    "    }\n",
    "\n",
    "    if analysis_type == \"scheduler\":\n",
    "        # Group by scheduler\n",
    "        by_scheduler = {}\n",
    "        for result in results_list:\n",
    "            scheduler = result[\"scheduler\"]\n",
    "            if scheduler not in by_scheduler:\n",
    "                by_scheduler[scheduler] = []\n",
    "            by_scheduler[scheduler].append(result[\"time\"])\n",
    "\n",
    "        analysis[\"by_scheduler\"] = {\n",
    "            name: {\n",
    "                \"avg_time\": np.mean(times),\n",
    "                \"min_time\": min(times),\n",
    "                \"max_time\": max(times),\n",
    "                \"samples\": len(times),\n",
    "            }\n",
    "            for name, times in by_scheduler.items()\n",
    "        }\n",
    "\n",
    "    elif analysis_type == \"cfg\":\n",
    "        # Group by CFG scale\n",
    "        by_cfg = {}\n",
    "        for result in results_list:\n",
    "            cfg = result[\"cfg_scale\"]\n",
    "            if cfg not in by_cfg:\n",
    "                by_cfg[cfg] = []\n",
    "            by_cfg[cfg].append(result[\"time\"])\n",
    "\n",
    "        analysis[\"by_cfg\"] = {\n",
    "            cfg: {\"avg_time\": np.mean(times), \"samples\": len(times)}\n",
    "            for cfg, times in by_cfg.items()\n",
    "        }\n",
    "\n",
    "    return analysis\n",
    "\n",
    "\n",
    "# Analyze results\n",
    "scheduler_analysis = analyze_results(results, \"scheduler\")\n",
    "cfg_analysis = analyze_results(cfg_results, \"cfg\")\n",
    "\n",
    "print(\"\\n[Analysis] Performance Summary:\")\n",
    "print(\n",
    "    f\"  Scheduler test: {scheduler_analysis['total_images']} images, avg {scheduler_analysis['avg_time']:.2f}s\"\n",
    ")\n",
    "print(\n",
    "    f\"  CFG test: {cfg_analysis['total_images']} images, avg {cfg_analysis['avg_time']:.2f}s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e665b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# [8] Create Comparison Grid (Memory Efficient)\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def create_comparison_grid(results_subset, title, max_images=9):\n",
    "    \"\"\"Create memory-efficient comparison grid\"\"\"\n",
    "    if len(results_subset) == 0:\n",
    "        return None\n",
    "\n",
    "    # Limit number of images to prevent memory issues\n",
    "    subset = results_subset[:max_images]\n",
    "\n",
    "    # Calculate grid size\n",
    "    cols = min(3, len(subset))\n",
    "    rows = (len(subset) + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))\n",
    "    if rows == 1 and cols == 1:\n",
    "        axes = [axes]\n",
    "    elif rows == 1:\n",
    "        axes = axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for i, result in enumerate(subset):\n",
    "        if i < len(axes):\n",
    "            axes[i].imshow(result[\"image\"])\n",
    "            axes[i].set_title(\n",
    "                f\"{result['scheduler']}\\n{result['steps']} steps, CFG {result['cfg_scale']}\\n{result['time']:.2f}s\",\n",
    "                fontsize=10,\n",
    "            )\n",
    "            axes[i].axis(\"off\")\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for i in range(len(subset), len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(title, fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save grid\n",
    "    grid_filename = f\"{title.lower().replace(' ', '_')}_grid.png\"\n",
    "    plt.savefig(output_dir / grid_filename, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    return grid_filename\n",
    "\n",
    "\n",
    "# Create comparison grids (limit to prevent memory issues)\n",
    "if results:\n",
    "    scheduler_grid = create_comparison_grid(\n",
    "        results[:9], \"SD1.5 Scheduler Comparison\", max_images=9\n",
    "    )\n",
    "\n",
    "if cfg_results:\n",
    "    cfg_grid = create_comparison_grid(\n",
    "        cfg_results[:6], \"CFG Scale Impact Analysis\", max_images=6\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e4c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# [9] Smoke Test (CI Compatible)\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def smoke_test():\n",
    "    \"\"\"Minimal smoke test for CI/CD\"\"\"\n",
    "    print(\"\\n[Smoke Test] Quick validation...\")\n",
    "\n",
    "    try:\n",
    "        # Single quick generation\n",
    "        smoke_result = benchmark_generation(\n",
    "            sd15_pipe, \"DPMSolverMultistep\", 10, 7.5, 42\n",
    "        )\n",
    "\n",
    "        # Basic validation\n",
    "        assert smoke_result[\"image\"].size == (512, 512), \"Image size incorrect\"\n",
    "        assert smoke_result[\"time\"] > 0, \"Generation time invalid\"\n",
    "        assert 0 < smoke_result[\"time\"] < 60, \"Generation took too long\"\n",
    "\n",
    "        print(f\"  ‚úì Smoke test passed: {smoke_result['time']:.2f}s\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Smoke test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Run smoke test\n",
    "smoke_passed = smoke_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862843a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# [10] Export Results & Metrics JSON\n",
    "# =============================================================================\n",
    "\n",
    "# Prepare export data (exclude PIL images for JSON serialization)\n",
    "export_data = {\n",
    "    \"experiment_info\": {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"config\": TEST_CONFIG,\n",
    "        \"scheduler_configs\": SCHEDULER_CONFIGS,\n",
    "        \"cfg_scales\": CFG_SCALES,\n",
    "        \"smoke_mode\": TEST_CONFIG[\"smoke_mode\"],\n",
    "    },\n",
    "    \"performance_analysis\": {\n",
    "        \"scheduler_analysis\": scheduler_analysis,\n",
    "        \"cfg_analysis\": cfg_analysis,\n",
    "    },\n",
    "    \"results_summary\": {\n",
    "        \"total_scheduler_tests\": len(results),\n",
    "        \"total_cfg_tests\": len(cfg_results),\n",
    "        \"smoke_test_passed\": smoke_passed,\n",
    "    },\n",
    "    \"recommendations\": {\n",
    "        \"fast_quality\": {\"scheduler\": \"DPMSolverMultistep\", \"steps\": 15, \"cfg\": 7.5},\n",
    "        \"balanced\": {\"scheduler\": \"DPMSolverMultistep\", \"steps\": 25, \"cfg\": 7.5},\n",
    "        \"high_quality\": {\"scheduler\": \"DPMSolverMultistep\", \"steps\": 50, \"cfg\": 7.5},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save metrics\n",
    "metrics_file = output_dir / \"metrics.json\"\n",
    "with open(metrics_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n[Export] Results saved to {output_dir}\")\n",
    "print(f\"  - Metrics: {metrics_file}\")\n",
    "print(f\"  - Images: {len(results + cfg_results)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# [11] Summary & Parameter Recipes\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä SCHEDULER/CFG COMPARISON SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n‚úÖ **Completed:**\")\n",
    "print(f\"   ‚Ä¢ {len(results)} scheduler comparison images\")\n",
    "print(f\"   ‚Ä¢ {len(cfg_results)} CFG scale test images\")\n",
    "print(f\"   ‚Ä¢ Performance analysis & timing benchmarks\")\n",
    "print(f\"   ‚Ä¢ {'‚úì' if smoke_passed else '‚úó'} Smoke test validation\")\n",
    "\n",
    "print(f\"\\nüéØ **Key Concepts Learned:**\")\n",
    "print(f\"   ‚Ä¢ Scheduler trade-offs: Speed vs Quality vs Consistency\")\n",
    "print(\n",
    "    f\"   ‚Ä¢ CFG Scale impact: 3.5-5.0 (subtle) ‚Üí 7.5 (balanced) ‚Üí 10+ (strong but potential artifacts)\"\n",
    ")\n",
    "print(f\"   ‚Ä¢ Memory optimization: attention_slicing + cpu_offload for 8-12GB VRAM\")\n",
    "print(f\"   ‚Ä¢ Reproducibility: Fixed seeds + config export for consistent results\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  **Common Pitfalls:**\")\n",
    "print(f\"   ‚Ä¢ Too high CFG (>12) ‚Üí oversaturated, artifact-prone results\")\n",
    "print(f\"   ‚Ä¢ Wrong scheduler for steps count ‚Üí poor convergence\")\n",
    "print(f\"   ‚Ä¢ Missing memory optimizations ‚Üí OOM on lower VRAM\")\n",
    "print(f\"   ‚Ä¢ Not saving configs ‚Üí irreproducible experiments\")\n",
    "\n",
    "print(f\"\\nüöÄ **Next Steps:**\")\n",
    "print(f\"   ‚Ä¢ Apply these recipes to ControlNet conditioning\")\n",
    "print(f\"   ‚Ä¢ Test same parameters on SDXL (different optimal ranges)\")\n",
    "print(f\"   ‚Ä¢ Use optimal configs for LoRA training in Stage 3\")\n",
    "print(f\"   ‚Ä¢ Integrate into batch pipeline configs\")\n",
    "\n",
    "print(f\"\\nüìÅ **Git Integration:**\")\n",
    "print(f\"   Branch: feature/s1/nb-sd-samplers-cfg\")\n",
    "print(f\"   Files: notebooks/t2i/10_sd/nb-sd-samplers-cfg.ipynb\")\n",
    "print(f\"   Output: outputs/scheduler_comparison/ (not committed)\")\n",
    "\n",
    "# Cleanup to free VRAM\n",
    "del sd15_pipe\n",
    "torch.cuda.empty_cache()\n",
    "print(f\"\\nüßπ Pipeline cleanup completed - VRAM freed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
