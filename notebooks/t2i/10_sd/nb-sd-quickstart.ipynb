{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ee4108",
   "metadata": {},
   "source": [
    "# nb-sd-quickstart.ipynb - SD1.5/SDXL Âü∫Á§éÊé®Ë´ñÂÖ•ÈñÄ\n",
    "\n",
    "## GoalsÔºàÂ≠∏ÁøíÁõÆÊ®ôÔºâ\n",
    "1. Âª∫Á´ã SD1.5/SDXL Âü∫Á§éÊé®Ë´ñËÉΩÂäõÔºåÊéåÊè°ÂÖ©Â§ß‰∏ªÊµÅ SD Ê®°ÂûãÁöÑËºâÂÖ•ËàáÁîüÂúñÊµÅÁ®ã\n",
    "2. ÁêÜËß£Ë®òÊÜ∂È´îÁÆ°ÁêÜÁ≠ñÁï•ÔºåÂ≠∏ÊúÉ FP16„ÄÅattention slicing„ÄÅCPU offload Á≠â Low-VRAM ÊäÄË°ì  \n",
    "3. ÊéåÊè°Ê†∏ÂøÉÂèÉÊï∏Ë™øÂÑ™ÔºåÁêÜËß£ steps„ÄÅCFG scale„ÄÅseed Â∞çÂúñÂÉèÂìÅË≥™ÁöÑÂΩ±Èüø\n",
    "4. Âª∫Á´ãÂèØÈáçÁèæÁöÑÂØ¶È©óÊµÅÁ®ãÔºåÈÖçÁΩÆÂ§ñÂåñ„ÄÅÁµêÊûúË®òÈåÑ„ÄÅA/B Â∞çÁÖß\n",
    "5. ÁÇ∫ÂæåÁ∫åÈÄ≤ÈöéÂ≠∏ÁøíÂ•†Âü∫ÔºåÁÜüÊÇâ diffusers ÁîüÊÖãËàá HuggingFace Hub Êï¥Âêà\n",
    "\n",
    "## PrerequisitesÔºàÂâçÁΩÆÊ¢ù‰ª∂Ôºâ\n",
    "- **VRAM**: ÊúÄÂ∞è 6GB (SD1.5: 4GB, SDXL: 6GB)ÔºåÊé®Ëñ¶ 8GB+\n",
    "- **Storage**: ~10GB for models cache\n",
    "- **Packages**: diffusers[torch], transformers, accelerate, xformers\n",
    "- **Optional**: wandb (ÂØ¶È©óË®òÈåÑ), compel (prompt weighting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [1] Shared Cache Bootstrap\n",
    "import os, pathlib, torch\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Shared cache configuration (Ë§áË£ΩÂà∞ÊØèÊú¨ notebook)\n",
    "AI_CACHE_ROOT = os.getenv(\"AI_CACHE_ROOT\", \"../ai_warehouse/cache\")\n",
    "\n",
    "for k, v in {\n",
    "    \"HF_HOME\": f\"{AI_CACHE_ROOT}/hf\",\n",
    "    \"TRANSFORMERS_CACHE\": f\"{AI_CACHE_ROOT}/hf/transformers\",\n",
    "    \"HF_DATASETS_CACHE\": f\"{AI_CACHE_ROOT}/hf/datasets\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\": f\"{AI_CACHE_ROOT}/hf/hub\",\n",
    "    \"TORCH_HOME\": f\"{AI_CACHE_ROOT}/torch\",\n",
    "}.items():\n",
    "    os.environ[k] = v\n",
    "    pathlib.Path(v).mkdir(parents=True, exist_ok=True)\n",
    "print(\"[Cache]\", AI_CACHE_ROOT, \"| GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9314a",
   "metadata": {},
   "source": [
    "Cell 2: Package Installation & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4299dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "import subprocess, sys\n",
    "\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package.split(\"[\")[0])  # Handle extras like diffusers[torch]\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "\n",
    "packages = [\n",
    "    \"diffusers[torch]>=0.30.0\",\n",
    "    \"transformers>=4.42\",\n",
    "    \"accelerate>=0.33\",\n",
    "    \"xformers\",  # For memory efficiency\n",
    "    \"compel\",  # For prompt weighting\n",
    "]\n",
    "\n",
    "for pkg in packages:\n",
    "    install_if_missing(pkg)\n",
    "\n",
    "print(\"‚úÖ All packages ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620d940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import torch\n",
    "from diffusers import (\n",
    "    StableDiffusionPipeline,\n",
    "    StableDiffusionXLPipeline,\n",
    "    DPMSolverMultistepScheduler,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    ")\n",
    "from compel import Compel\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
    "SMOKE_MODE = os.getenv(\"SMOKE_MODE\", \"false\").lower() == \"true\"\n",
    "\n",
    "print(f\"Device: {DEVICE}, Dtype: {DTYPE}, Smoke Mode: {SMOKE_MODE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d418d",
   "metadata": {},
   "source": [
    "Cell 3: SD1.5 Pipeline Setup (Low-VRAM Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d67238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SD1.5 Pipeline with memory optimizations\n",
    "MODEL_ID_SD15 = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "\n",
    "def create_sd15_pipeline(enable_optimizations=True):\n",
    "    \"\"\"Create SD1.5 pipeline with optional memory optimizations\"\"\"\n",
    "\n",
    "    # Load pipeline with FP16 for memory efficiency\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        MODEL_ID_SD15,\n",
    "        torch_dtype=DTYPE,\n",
    "        use_safetensors=True,\n",
    "        variant=\"fp16\" if DTYPE == torch.float16 else None,\n",
    "    )\n",
    "\n",
    "    if enable_optimizations and DEVICE == \"cuda\":\n",
    "        # Memory optimizations for low-VRAM GPUs\n",
    "        pipe.enable_attention_slicing()  # Reduce memory usage\n",
    "        pipe.enable_vae_slicing()  # VAE memory optimization\n",
    "\n",
    "        try:\n",
    "            pipe.enable_xformers_memory_efficient_attention()  # Faster + less memory\n",
    "            print(\"‚úÖ xFormers enabled\")\n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è  xFormers not available, using default attention\")\n",
    "\n",
    "    pipe = pipe.to(DEVICE)\n",
    "\n",
    "    # Use more efficient scheduler\n",
    "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "        pipe.scheduler.config, use_karras_sigmas=True\n",
    "    )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "# Create SD1.5 pipeline\n",
    "print(\"Loading SD1.5 pipeline...\")\n",
    "start_time = time.time()\n",
    "sd15_pipe = create_sd15_pipeline()\n",
    "load_time = time.time() - start_time\n",
    "print(f\"‚úÖ SD1.5 loaded in {load_time:.2f}s\")\n",
    "\n",
    "# Check VRAM usage\n",
    "if DEVICE == \"cuda\":\n",
    "    memory_used = torch.cuda.memory_allocated() / 1e9\n",
    "    print(f\"üìä VRAM used: {memory_used:.2f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9171d61",
   "metadata": {},
   "source": [
    "Cell 4: SD1.5 Basic Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SD1.5 basic inference with parameter exploration\n",
    "def generate_sd15(\n",
    "    prompt,\n",
    "    negative_prompt=\"\",\n",
    "    width=512,\n",
    "    height=512,\n",
    "    num_inference_steps=20,\n",
    "    guidance_scale=7.5,\n",
    "    seed=42,\n",
    "    num_images=1,\n",
    "):\n",
    "    \"\"\"Generate images with SD1.5\"\"\"\n",
    "\n",
    "    # Set generator for reproducibility\n",
    "    generator = torch.Generator(device=DEVICE).manual_seed(seed)\n",
    "\n",
    "    # Generate\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        result = sd15_pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator,\n",
    "            num_images_per_prompt=num_images,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    return {\n",
    "        \"images\": result.images,\n",
    "        \"metadata\": {\n",
    "            \"model\": \"SD1.5\",\n",
    "            \"prompt\": prompt,\n",
    "            \"negative_prompt\": negative_prompt,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"steps\": num_inference_steps,\n",
    "            \"cfg\": guidance_scale,\n",
    "            \"seed\": seed,\n",
    "            \"inference_time\": inference_time,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# Test with a simple prompt\n",
    "test_prompt = (\n",
    "    \"a serene landscape with mountains and lake, golden hour lighting, photorealistic\"\n",
    ")\n",
    "test_negative = \"blurry, low quality, distorted\"\n",
    "\n",
    "print(\"üé® Generating SD1.5 test image...\")\n",
    "steps = 5 if SMOKE_MODE else 20  # Reduce steps for CI testing\n",
    "\n",
    "result_sd15 = generate_sd15(\n",
    "    prompt=test_prompt,\n",
    "    negative_prompt=test_negative,\n",
    "    num_inference_steps=steps,\n",
    "    guidance_scale=7.5,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Generated in {result_sd15['metadata']['inference_time']:.2f}s\")\n",
    "\n",
    "# Display result\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.imshow(result_sd15[\"images\"][0])\n",
    "ax.set_title(f\"SD1.5 - Steps: {steps}, CFG: 7.5\")\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print metadata\n",
    "print(\"üìã Generation metadata:\")\n",
    "print(json.dumps(result_sd15[\"metadata\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004620ef",
   "metadata": {},
   "source": [
    "Cell 5: SDXL Pipeline Setup (Advanced Memory Management)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff536da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDXL Pipeline with aggressive memory optimizations\n",
    "MODEL_ID_SDXL = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "\n",
    "\n",
    "def create_sdxl_pipeline(enable_cpu_offload=False):\n",
    "    \"\"\"Create SDXL pipeline with optional CPU offloading for low-VRAM\"\"\"\n",
    "\n",
    "    # Load with memory-efficient settings\n",
    "    pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "        MODEL_ID_SDXL,\n",
    "        torch_dtype=DTYPE,\n",
    "        use_safetensors=True,\n",
    "        variant=\"fp16\" if DTYPE == torch.float16 else None,\n",
    "    )\n",
    "\n",
    "    if DEVICE == \"cuda\":\n",
    "        # Enable all memory optimizations\n",
    "        pipe.enable_attention_slicing()\n",
    "        pipe.enable_vae_slicing()\n",
    "\n",
    "        try:\n",
    "            pipe.enable_xformers_memory_efficient_attention()\n",
    "            print(\"‚úÖ xFormers enabled for SDXL\")\n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è  xFormers not available\")\n",
    "\n",
    "        if enable_cpu_offload:\n",
    "            # For GPUs with < 8GB VRAM\n",
    "            pipe.enable_sequential_cpu_offload()\n",
    "            print(\"‚úÖ CPU offload enabled\")\n",
    "        else:\n",
    "            pipe = pipe.to(DEVICE)\n",
    "\n",
    "    # Use efficient scheduler\n",
    "    pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "# Check available VRAM and decide on CPU offload\n",
    "if DEVICE == \"cuda\":\n",
    "    total_vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    use_cpu_offload = total_vram < 10  # Use offload for <10GB VRAM\n",
    "    print(f\"üìä Total VRAM: {total_vram:.1f}GB, CPU offload: {use_cpu_offload}\")\n",
    "else:\n",
    "    use_cpu_offload = False\n",
    "\n",
    "print(\"Loading SDXL pipeline...\")\n",
    "start_time = time.time()\n",
    "sdxl_pipe = create_sdxl_pipeline(enable_cpu_offload=use_cpu_offload)\n",
    "load_time = time.time() - start_time\n",
    "print(f\"‚úÖ SDXL loaded in {load_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a273dd8",
   "metadata": {},
   "source": [
    "Cell 6: SDXL Basic Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99447841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDXL inference function\n",
    "def generate_sdxl(\n",
    "    prompt,\n",
    "    negative_prompt=\"\",\n",
    "    width=1024,\n",
    "    height=1024,\n",
    "    num_inference_steps=20,\n",
    "    guidance_scale=5.0,  # SDXL typically uses lower CFG\n",
    "    seed=42,\n",
    "    num_images=1,\n",
    "):\n",
    "    \"\"\"Generate images with SDXL\"\"\"\n",
    "\n",
    "    generator = torch.Generator(device=DEVICE).manual_seed(seed)\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        result = sdxl_pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=generator,\n",
    "            num_images_per_prompt=num_images,\n",
    "            return_dict=True,\n",
    "        )\n",
    "\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    return {\n",
    "        \"images\": result.images,\n",
    "        \"metadata\": {\n",
    "            \"model\": \"SDXL\",\n",
    "            \"prompt\": prompt,\n",
    "            \"negative_prompt\": negative_prompt,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"steps\": num_inference_steps,\n",
    "            \"cfg\": guidance_scale,\n",
    "            \"seed\": seed,\n",
    "            \"inference_time\": inference_time,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "# Test SDXL with same prompt for comparison\n",
    "print(\"üé® Generating SDXL test image...\")\n",
    "\n",
    "# Use smaller resolution and fewer steps in smoke mode\n",
    "width = 512 if SMOKE_MODE else 1024\n",
    "height = 512 if SMOKE_MODE else 1024\n",
    "steps = 5 if SMOKE_MODE else 20\n",
    "\n",
    "result_sdxl = generate_sdxl(\n",
    "    prompt=test_prompt,\n",
    "    negative_prompt=test_negative,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    num_inference_steps=steps,\n",
    "    guidance_scale=5.0,  # Lower CFG for SDXL\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Generated in {result_sdxl['metadata']['inference_time']:.2f}s\")\n",
    "\n",
    "# Display result\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.imshow(result_sdxl[\"images\"][0])\n",
    "ax.set_title(f\"SDXL - {width}x{height}, Steps: {steps}, CFG: 5.0\")\n",
    "ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìã SDXL metadata:\")\n",
    "print(json.dumps(result_sdxl[\"metadata\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fc7aef",
   "metadata": {},
   "source": [
    "Cell 7: Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5845a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare SD1.5 vs SDXL results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# SD1.5 result\n",
    "axes[0].imshow(result_sd15[\"images\"][0])\n",
    "axes[0].set_title(\n",
    "    f\"SD1.5 (512x512)\\nSteps: {result_sd15['metadata']['steps']}, CFG: {result_sd15['metadata']['cfg']}\"\n",
    ")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# SDXL result\n",
    "axes[1].imshow(result_sdxl[\"images\"][0])\n",
    "axes[1].set_title(\n",
    "    f\"SDXL ({result_sdxl['metadata']['width']}x{result_sdxl['metadata']['height']})\\nSteps: {result_sdxl['metadata']['steps']}, CFG: {result_sdxl['metadata']['cfg']}\"\n",
    ")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Performance comparison\n",
    "print(\"\\nüìä Performance Comparison:\")\n",
    "print(f\"SD1.5:  {result_sd15['metadata']['inference_time']:.2f}s\")\n",
    "print(f\"SDXL:   {result_sdxl['metadata']['inference_time']:.2f}s\")\n",
    "print(\n",
    "    f\"Ratio:  {result_sdxl['metadata']['inference_time'] / result_sd15['metadata']['inference_time']:.1f}x slower\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b963832",
   "metadata": {},
   "source": [
    "Cell 8: Parameter Exploration (Steps & CFG Scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cce7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter exploration: Steps vs Quality vs Speed\n",
    "def parameter_exploration(pipe_func, model_name, base_prompt):\n",
    "    \"\"\"Explore different steps and CFG values\"\"\"\n",
    "\n",
    "    if SMOKE_MODE:\n",
    "        step_values = [5, 10]\n",
    "        cfg_values = [3.5, 7.5]\n",
    "    else:\n",
    "        step_values = [10, 15, 20, 28]\n",
    "        cfg_values = [3.5, 5.0, 7.5, 10.0]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for steps in step_values:\n",
    "        for cfg in cfg_values:\n",
    "            print(f\"üîÑ Testing {model_name}: steps={steps}, cfg={cfg}\")\n",
    "\n",
    "            result = pipe_func(\n",
    "                prompt=base_prompt,\n",
    "                num_inference_steps=steps,\n",
    "                guidance_scale=cfg,\n",
    "                width=512,\n",
    "                height=512,  # Keep resolution consistent\n",
    "                seed=12345,  # Fixed seed for comparison\n",
    "            )\n",
    "\n",
    "            key = f\"steps_{steps}_cfg_{cfg}\"\n",
    "            results[key] = {\n",
    "                \"image\": result[\"images\"][0],\n",
    "                \"time\": result[\"metadata\"][\"inference_time\"],\n",
    "                \"steps\": steps,\n",
    "                \"cfg\": cfg,\n",
    "            }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Explore SD1.5 parameters\n",
    "exploration_prompt = (\n",
    "    \"a cyberpunk cityscape at night, neon lights, detailed architecture\"\n",
    ")\n",
    "\n",
    "print(\"üî¨ SD1.5 Parameter Exploration...\")\n",
    "sd15_exploration = parameter_exploration(generate_sd15, \"SD1.5\", exploration_prompt)\n",
    "\n",
    "# Display results in grid\n",
    "n_steps = 2 if SMOKE_MODE else 4\n",
    "n_cfg = 2 if SMOKE_MODE else 4\n",
    "\n",
    "fig, axes = plt.subplots(n_steps, n_cfg, figsize=(16, 12))\n",
    "if n_steps == 1:\n",
    "    axes = [axes]\n",
    "if n_cfg == 1:\n",
    "    axes = [[ax] for ax in axes]\n",
    "\n",
    "step_values = [5, 10] if SMOKE_MODE else [10, 15, 20, 28]\n",
    "cfg_values = [3.5, 7.5] if SMOKE_MODE else [3.5, 5.0, 7.5, 10.0]\n",
    "\n",
    "for i, steps in enumerate(step_values):\n",
    "    for j, cfg in enumerate(cfg_values):\n",
    "        key = f\"steps_{steps}_cfg_{cfg}\"\n",
    "        if key in sd15_exploration:\n",
    "            result = sd15_exploration[key]\n",
    "            axes[i][j].imshow(result[\"image\"])\n",
    "            axes[i][j].set_title(f\"Steps: {steps}, CFG: {cfg}\\n{result['time']:.1f}s\")\n",
    "            axes[i][j].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"SD1.5 Parameter Exploration\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print timing analysis\n",
    "print(\"\\n‚è±Ô∏è  Timing Analysis:\")\n",
    "for key, result in sd15_exploration.items():\n",
    "    print(f\"{key}: {result['time']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976df289",
   "metadata": {},
   "source": [
    "Cell 9: Save Results & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and configuration for reproducibility\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Create output directory\n",
    "output_dir = (\n",
    "    Path(\"outputs\") / \"sd_quickstart\" / datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    ")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Save images with metadata\n",
    "def save_result(result, filename_prefix):\n",
    "    \"\"\"Save image and metadata\"\"\"\n",
    "    image = result[\"images\"][0]\n",
    "    metadata = result[\"metadata\"]\n",
    "\n",
    "    # Save image\n",
    "    image_path = output_dir / f\"{filename_prefix}.png\"\n",
    "    image.save(image_path)\n",
    "\n",
    "    # Save metadata\n",
    "    meta_path = output_dir / f\"{filename_prefix}_metadata.json\"\n",
    "    with open(meta_path, \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "    print(f\"üíæ Saved: {image_path}\")\n",
    "    return image_path\n",
    "\n",
    "\n",
    "# Save main results\n",
    "sd15_path = save_result(result_sd15, \"sd15_basic\")\n",
    "sdxl_path = save_result(result_sdxl, \"sdxl_basic\")\n",
    "\n",
    "# Save exploration results (sample)\n",
    "if not SMOKE_MODE:\n",
    "    for i, (key, result) in enumerate(list(sd15_exploration.items())[:4]):\n",
    "        save_path = output_dir / f\"exploration_{key}.png\"\n",
    "        result[\"image\"].save(save_path)\n",
    "\n",
    "# Save experiment configuration\n",
    "config = {\n",
    "    \"experiment\": \"SD Quickstart Comparison\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"models\": {\"sd15\": MODEL_ID_SD15, \"sdxl\": MODEL_ID_SDXL},\n",
    "    \"device\": DEVICE,\n",
    "    \"dtype\": str(DTYPE),\n",
    "    \"optimizations\": {\n",
    "        \"attention_slicing\": True,\n",
    "        \"vae_slicing\": True,\n",
    "        \"xformers\": True,\n",
    "        \"cpu_offload\": use_cpu_offload,\n",
    "    },\n",
    "    \"test_prompt\": test_prompt,\n",
    "    \"smoke_mode\": SMOKE_MODE,\n",
    "}\n",
    "\n",
    "config_path = output_dir / \"experiment_config.json\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"\\nüìÅ Results saved to: {output_dir}\")\n",
    "print(f\"üìÑ Config saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd50e5d",
   "metadata": {},
   "source": [
    "Cell 10: Memory Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e4906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"Clean up GPU memory\"\"\"\n",
    "    # Clear variables\n",
    "    del sd15_pipe, sdxl_pipe\n",
    "\n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "    if DEVICE == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "        memory_after = torch.cuda.memory_allocated() / 1e9\n",
    "        print(f\"üßπ Memory after cleanup: {memory_after:.2f}GB\")\n",
    "\n",
    "\n",
    "cleanup_memory()\n",
    "print(\"‚úÖ Memory cleanup completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0588b931",
   "metadata": {},
   "source": [
    "\n",
    "## SummaryÔºàÂÆåÊàêÊëòË¶ÅÔºâ\n",
    "\n",
    "‚úÖ **ÂÆåÊàêÈ†ÖÁõÆ**:\n",
    "- SD1.5/SDXL Âü∫Á§éÊé®Ë´ñÊµÅÁ®ãÂª∫Á´ã\n",
    "- Ë®òÊÜ∂È´îÂÑ™ÂåñÁ≠ñÁï•ÂØ¶‰ΩúÔºàFP16„ÄÅattention slicing„ÄÅCPU offloadÔºâ\n",
    "- Ê†∏ÂøÉÂèÉÊï∏Êé¢Á¥¢Ôºàsteps„ÄÅCFG scaleÔºâ\n",
    "- ÂèØÈáçÁèæÂØ¶È©óÊ°ÜÊû∂Ôºàseed„ÄÅÈÖçÁΩÆË®òÈåÑÔºâ\n",
    "- ÊïàËÉΩÂ∞çÊØîÂàÜÊûê\n",
    "\n",
    "## Key ConceptsÔºàÊ†∏ÂøÉÊ¶ÇÂøµÔºâ\n",
    "\n",
    "1. **Ë®òÊÜ∂È´îÁÆ°ÁêÜ**: attention_slicing„ÄÅvae_slicing„ÄÅcpu_offload ÁöÑÈÅ©Áî®ÊÉÖÂ¢É\n",
    "2. **ÂèÉÊï∏Ë™øÂÑ™**: Steps (Êé®Ë´ñÂìÅË≥™ vs ÈÄüÂ∫¶)„ÄÅCFG Scale (ÂâµÊÑèÊÄß vs ‰∏ÄËá¥ÊÄß)\n",
    "3. **Ê®°ÂûãÂ∑ÆÁï∞**: SD1.5 (512px, Âø´ÈÄü) vs SDXL (1024px, È´òÂìÅË≥™)\n",
    "4. **ÂèØÈáçÁèæÊÄß**: Generator seeds„ÄÅÈÖçÁΩÆÂ§ñÂåñÁöÑÈáçË¶ÅÊÄß\n",
    "\n",
    "## Common PitfallsÔºàÂ∏∏Ë¶ãÂïèÈ°åÔºâ\n",
    "\n",
    "1. **VRAM ‰∏çË∂≥**: Êú™ÂïüÁî®Ë®òÊÜ∂È´îÂÑ™ÂåñÈÅ∏È†Ö\n",
    "2. **ÈÄüÂ∫¶Á∑©ÊÖ¢**: ÈÅéÈ´òÁöÑËß£ÊûêÂ∫¶ÊàñÊ≠•Êï∏Ë®≠ÂÆö\n",
    "3. **ÁµêÊûú‰∏çÁ©©ÂÆö**: Êú™Ë®≠ÂÆö seed ÊàñÊ∏ÖÈô§Âø´ÂèñÂïèÈ°å\n",
    "4. **ÁâàÊú¨Ë°ùÁ™Å**: diffusers/transformers ÁâàÊú¨‰∏çÂåπÈÖç\n",
    "\n",
    "## Next StepsÔºà‰∏ã‰∏ÄÊ≠•Ôºâ\n",
    "\n",
    "1. **Scheduler Êé¢Á¥¢**: ÂòóË©¶‰∏çÂêå scheduler Â∞çÁîüÂúñÂìÅË≥™ÁöÑÂΩ±Èüø\n",
    "2. **Prompt Engineering**: Â≠∏ÁøíÊúâÊïàÁöÑ prompt ÁµêÊßãËàáÊäÄÂ∑ß\n",
    "3. **ControlNet Êï¥Âêà**: ÁÇ∫ Stage 2 ÁöÑÊ¢ù‰ª∂ÊéßÂà∂ÂÅöÊ∫ñÂÇô\n",
    "4. **ÊâπÊ¨°Êé®Ë´ñ**: ÈñãÁôº CSV/JSON È©ÖÂãïÁöÑÊâπÊ¨°ÁîüÂúñÊµÅÁ®ã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b8d48d",
   "metadata": {},
   "source": [
    "Smoke Test Ê∏¨Ë©¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf950645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke test for CI/CD pipeline\n",
    "def smoke_test():\n",
    "    \"\"\"Quick test to verify basic functionality\"\"\"\n",
    "    print(\"üß™ Running smoke test...\")\n",
    "\n",
    "    # Test with minimal parameters\n",
    "    quick_result = generate_sd15(\n",
    "        prompt=\"a simple cat\",\n",
    "        num_inference_steps=2,  # Minimal steps\n",
    "        guidance_scale=5.0,\n",
    "        width=256,\n",
    "        height=256,  # Small resolution\n",
    "        seed=999,\n",
    "    )\n",
    "\n",
    "    # Verify image was generated\n",
    "    assert len(quick_result[\"images\"]) == 1\n",
    "    assert quick_result[\"images\"][0].size == (256, 256)\n",
    "\n",
    "    print(\"‚úÖ Smoke test passed!\")\n",
    "    return quick_result\n",
    "\n",
    "\n",
    "if SMOKE_MODE:\n",
    "    smoke_result = smoke_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
