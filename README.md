# ğŸ¨ T2I-practice-lab

**T2I-practice-lab** is a structured practice and research repository focused on **Text-to-Image (T2I) generation models** and **LLM Ã— RAG applications**.
The project integrates **PyTorch foundations**, **Transformer/LLM training**, **fine-tuning methods**, **retrieval-augmented generation (RAG)**, and **deployment pipelines** into a coherent learning lab.
It serves both as a **personal portfolio** and a **comprehensive training ground** for mastering modern AI systems.

---

## ğŸ“ Project Structure

```bash
T2I-practice-lab/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env.example               # Environment variables (HF_TOKEN, OPENAI_API_KEY)
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ environment.yml            # Conda environment setup
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ model_configs.yaml
â”‚   â”œâ”€â”€ cache_settings.yaml
â”‚   â””â”€â”€ evaluation_configs.yaml
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ part_a_foundations/        # PyTorch & basic ML
â”‚   â”œâ”€â”€ part_b_transformer_hf/     # Transformers + Hugging Face
â”‚   â”œâ”€â”€ part_c_llm_applications/   # LLM apps (agents, evaluation, safety)
â”‚   â”œâ”€â”€ part_d_finetuning/         # Fine-tuning (LoRA, QLoRA, DPO, RLHF)
â”‚   â”œâ”€â”€ part_e_rag_agents/         # RAG + multi-agent collaboration
â”‚   â””â”€â”€ part_f_webui_api/          # WebUI & deployment
â”‚
â”œâ”€â”€ shared_utils/                  # Reusable Python utilities
â”œâ”€â”€ tests/                         # Validation & smoke tests
â””â”€â”€ docs/                          # Documentation (setup, roadmap, FAQ)
````

> See [`docs/learning_roadmap.md`](docs/learning_roadmap.md) for the **full 32+ notebook learning sequence**.

---

## âš™ï¸ Environment Setup

### Using Conda

```bash
conda env create -f environment.yml
conda activate t2i-lab
```

### Using pip

```bash
pip install -r requirements.txt
```

### Environment Variables

Copy `.env.example` â†’ `.env` and set the following:

```bash
HF_TOKEN=your_huggingface_token
OPENAI_API_KEY=your_openai_key
```

---

## ğŸ“˜ Learning Roadmap

The project is divided into **6 stages** (32+ notebooks):

* **Part A: Foundations** â€“ PyTorch basics, CNNs, RNNs
* **Part B: Transformers & Hugging Face** â€“ attention, datasets, model loading
* **Part C: LLM Applications** â€“ function calling, reasoning, evaluation, agents
* **Part D: Fine-tuning** â€“ LoRA, QLoRA, adapters, dataset curation, RLHF
* **Part E: RAG Ã— Agents** â€“ FAISS retrieval, multimodal RAG, multi-agent systems
* **Part F: WebUI & API** â€“ Gradio UI, FastAPI + Docker deployment

ğŸ”¥ **Priority Notebooks**:

* `nb13_function_calling_tools.ipynb`
* `nb26_rag_basic_faiss.ipynb`

---

## ğŸ”§ Shared Utilities

* `cache_manager.py` â€“ shared cache initialization
* `model_loader.py` â€“ unified low-VRAM model loading
* `evaluation_utils.py` â€“ evaluation metrics (ROUGE, BLEU, perplexity)
* `prompt_templates.py` â€“ standardized prompt dictionary

---

## ğŸš€ Git Workflow

We follow a **feature-branch Git Flow**:

```bash
# Start development
git checkout -b develop

# New feature (e.g., notebook nb13)
git checkout -b feature/nb13-function-calling
# ... implement notebook ...
git commit -m "feat(notebooks): add nb13 function calling with LangChain tools"
git checkout develop
git merge --no-ff feature/nb13-function-calling

# Stage release
git checkout main
git merge --no-ff develop
git tag -a "v1.0-stage-c" -m "Complete LLM Applications stage"
```

See \[Git Workflow Strategy]\(docs/Git Workflow Strategy & Branching Model.md) for details.

---

## ğŸ“‘ RAG Ã— Prompt Dictionary

This project integrates **RAG pipelines** with a **Prompt/Style Dictionary**:

* **Retrieval layer**: FAISS, Chroma, Weaviate backends
* **Augmentation layer**: context injection (chunking, summarization, hybrid search)
* **LLM inference**: DeepSeek-R1, Qwen, LLaMA, GPT (optional APIs)
* **Prompt Dictionary**: centralized YAML/JSON templates for style, tone, safety

> Example: `prompt_templates.py` ensures consistent style across all agents (e.g., academic reasoning, step-by-step explanations, multilingual support).

---

## ğŸ“¦ Release Strategy

* **Stage releases** aligned with notebook parts (A â†’ F).
* **Semantic versioning**:

  * `v1.0` = Core LLM Applications complete
  * `v2.0` = Fine-tuning + RAG integration
  * `v3.0` = WebUI + Deployment

---

## ğŸ¤ Contribution Guide

1. Fork the repo & create feature branch:

   ```bash
   git checkout -b feature/my-new-module
   ```
2. Add/modify notebooks or shared utilities.
3. Run tests in `/tests`.
4. Submit a Pull Request (PR).

---

## ğŸ“š References

* Hugging Face ğŸ¤— Transformers & Datasets
* PyTorch Lightning âš¡ for training loops
* FAISS, ChromaDB, Weaviate for retrieval
* Gradio, FastAPI, Docker for deployment

---

## ğŸ† Goal

By completing **T2I-practice-lab**, you will:

* Gain **foundational deep learning skills**
* Build **LLM + RAG systems** end-to-end
* Deploy **AI-powered WebUI/API prototypes**
* Establish a **solid portfolio of practical AI projects**

---